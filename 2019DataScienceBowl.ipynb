{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple, easy and fast and less overfitting solution with 460 features\n",
    "\n",
    "This notebook shows problem solving approach using LightGBM Regression and 890 features computed by bruno aquino in the following notebook which are later reduced to 460 features in my approach.\n",
    "\n",
    "https://www.kaggle.com/braquino/890-features\n",
    "\n",
    "It also uses the regression coefficients from following notebook by artgor.\n",
    "\n",
    "https://www.kaggle.com/artgor/quick-and-dirty-regression\n",
    "\n",
    "Apart from these i also have included resultant LightGBM parameters from exhaustive parameter tuning.\n",
    "\n",
    "If you find this notebook helpful please press that thumbs up button and thank you :)\n",
    "\n",
    "PLEASE NOTE THIS IMPORTANT POINT \"**DON'T BELIEVE IN PUBLIC LB**\" IT'S ONLY 14% of real data that's private!! We should build a model that's less overfittig and still finding the good results.\"\n",
    "\n",
    "Your score will be different for different submissions that's because of randomness in gradient boosting!\n",
    "and that's completely normal you must focus on reducing overfitting, gather as much data as possible and ofcourse reduce the number of features as much as possible without sacrificing model validation score and that's exactly what i've done below :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#####SOME BREAD BUTTER JAM IMPORTS!##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import re\n",
    "#AND SOME USEFULL IMPORTS\n",
    "import copy #deep copy porpuses\n",
    "import json #reading and manipulation of data\n",
    "from itertools import product #make some combinations, used for feature extraction and combinations\n",
    "from collections import Counter #counting the occurances, here used in feature extractions\n",
    "from tqdm import tqdm_notebook #for fancy looking progress\n",
    "from tqdm import tqdm #for fancy looking progress\n",
    "import datetime #for time related tasks\n",
    "import time #for time related tasks\n",
    "import lightgbm as lgb #star of the show\n",
    "from sklearn.preprocessing import LabelEncoder #Label encoding of categorical variables\n",
    "from sklearn.model_selection import GroupKFold #CV purposes\n",
    "from sklearn.metrics import classification_report, confusion_matrix #For helping with my favourite metric QWK\n",
    "from sklearn import metrics #self explanatory!\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some necessary settings**\n",
    "\n",
    "Warnings and other stuff you know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") #ignore all warnings we don't care!!\n",
    "pd.set_option('max_rows', 500) #for explanatory purposes\n",
    "pd.options.display.precision = 15 #set default display precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions read, encode and make features from each and every installation data one by one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission\n",
    "\n",
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0 \n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    time_spent_each_act = {t+\"_time\": 0 for t in titles}\n",
    "        \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        \n",
    "        if (session_type != 'Assessment'):\n",
    "            time_spent = int(session[\"game_time\"].iloc[-1] / 1000)\n",
    "            time_spent_each_act[inverse_transform[session_title] + \"_time\"] += time_spent\n",
    "        \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query('event_code == {}'.format(win_code[session_title]))\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(time_spent_each_act.copy())\n",
    "            \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it's the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get unique titles from train set finding proper mapping for label encoding and also have inverse mapping dict that will be used to make duration related features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n",
      "total 44 titles\n"
     ]
    }
   ],
   "source": [
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "labelEncoderTitle = LabelEncoder()\n",
    "labelEncoderTitle.fit(train[\"title\"].values)\n",
    "titles = labelEncoderTitle.classes_\n",
    "print(\"total {} titles\".format(len(titles)))\n",
    "numbers = labelEncoderTitle.transform(titles)\n",
    "inverse_transform = {}\n",
    "index = 0\n",
    "for number in numbers:\n",
    "    inverse_transform[number] = titles[index]\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17000/17000 [07:24<00:00, 38.25it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 21.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals\n",
    "\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get some features than can provide a brief about overall installation experiance of user**\n",
    "\n",
    "Based some important historical features which we have created using get_data function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "        \n",
    "    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "    features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n",
    "   \n",
    "    return reduce_train, reduce_test, features\n",
    "# call feature engineering function\n",
    "reduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDUCTION BEGINS\n",
    "\n",
    "**1. Remove features having constant value for approx. 99% of rows**\n",
    "\n",
    "These features are known as quansi-constant features and can lead to bad results in test set. Because model will not be able to make decision for new values it haven't seen while training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 features removed!\n"
     ]
    }
   ],
   "source": [
    "del_cols = []\n",
    "for col in reduce_train.columns.values:\n",
    "    counts = reduce_train[col].value_counts().iloc[0]\n",
    "    if (counts / reduce_train.shape[0]) >= 0.99:\n",
    "        del_cols.append(col)\n",
    "print(str(len(del_cols)) + \" features removed!\")\n",
    "reduce_train.drop(del_cols, inplace = True, axis = \"columns\")\n",
    "reduce_test.drop(del_cols, inplace = True, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Remove features having duplicate values for approx. 99% of rows**\n",
    "\n",
    "These duplicate features can lead to bad results in test set. Because model will find it difficult to make decision for different values of features it haven't seen while training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can uncomment following code and execute it but it will take a lot of time to iterate over all columns and find the duplicate ones so i have included the columns which are to be deleted in next cell :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'same_features = {}\\ncounter = 0 \\nfor i_col in tqdm(reduce_train.columns.values, total = len(reduce_train.columns.values)):\\n    for j_col in reduce_train.columns.values:\\n        if i_col == j_col:\\n            continue\\n        if i_col in same_features:\\n            if j_col in same_features[i_col]:\\n                continue\\n        if j_col in same_features:\\n            if i_col in same_features[j_col]:\\n                continue\\n        same = False\\n        for col in same_features:\\n            if i_col in same_features[col] and j_col in same_features[col]:\\n                same = True\\n        if same:\\n            continue\\n        same_amount = np.sum((reduce_train[i_col] == reduce_train[j_col]).astype(int)) / reduce_train.shape[0]\\n        if same_amount >= 0.99:\\n            if not i_col in same_features:\\n                same_features[i_col] = []\\n            same_features[i_col].append(j_col)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"same_features = {}\n",
    "counter = 0 \n",
    "for i_col in tqdm(reduce_train.columns.values, total = len(reduce_train.columns.values)):\n",
    "    for j_col in reduce_train.columns.values:\n",
    "        if i_col == j_col:\n",
    "            continue\n",
    "        if i_col in same_features:\n",
    "            if j_col in same_features[i_col]:\n",
    "                continue\n",
    "        if j_col in same_features:\n",
    "            if i_col in same_features[j_col]:\n",
    "                continue\n",
    "        same = False\n",
    "        for col in same_features:\n",
    "            if i_col in same_features[col] and j_col in same_features[col]:\n",
    "                same = True\n",
    "        if same:\n",
    "            continue\n",
    "        same_amount = np.sum((reduce_train[i_col] == reduce_train[j_col]).astype(int)) / reduce_train.shape[0]\n",
    "        if same_amount >= 0.99:\n",
    "            if not i_col in same_features:\n",
    "                same_features[i_col] = []\n",
    "            same_features[i_col].append(j_col)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same_features is a dict having following format:\n",
    "\n",
    "same_features[\"feature_t\"] = [list of all features shwoing 99% similarity to feature_t]\n",
    "\n",
    "and so only feature_t will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['37c53127',\n",
    " 'Scrub-A-Dub_2050',\n",
    " '65a38bf7',\n",
    " 'Cart Balancer (Assessment)_2000',\n",
    " 'Cart Balancer (Assessment)_2020',\n",
    " 'Pan Balance_3121',\n",
    " '8d84fa81',\n",
    " '51102b85',\n",
    " '15eb4a7d',\n",
    " 'Bird Measurer (Assessment)_3021',\n",
    " '7525289a',\n",
    " 'Bird Measurer (Assessment)_3121',\n",
    " 'cc5087a3',\n",
    " '4d911100',\n",
    " '25fa8af4',\n",
    " '7cf1bc53',\n",
    " 'Happy Camel_4090',\n",
    " 'cf82af56',\n",
    " 'All Star Sorting_4030',\n",
    " '3afde5dd',\n",
    " 'b012cd7f',\n",
    " 'Leaf Leader_2030',\n",
    " 'e79f3763',\n",
    " 'ecaab346',\n",
    " 'b2e5b0f1',\n",
    " 'Cart Balancer (Assessment)_3121',\n",
    " 'Cart Balancer (Assessment)_2010',\n",
    " 'b74258a0',\n",
    " '0db6d71d',\n",
    " 'Dino Drink_3120',\n",
    " '89aace00',\n",
    " 'e5734469',\n",
    " 'Mushroom Sorter (Assessment)_2010',\n",
    " 'Cart Balancer (Assessment)_4070',\n",
    " 'Scrub-A-Dub_2020',\n",
    " '3dfd4aa4',\n",
    " 'Mushroom Sorter (Assessment)_2035',\n",
    " '83c6c409',\n",
    " 'Happy Camel_2080',\n",
    " 'Chow Time_3121',\n",
    " 'Cart Balancer (Assessment)_4040',\n",
    " '3dcdda7f',\n",
    " 'Air Show_3121',\n",
    " 'Air Show_3021',\n",
    " '9b4001e4',\n",
    " 'Chest Sorter (Assessment)_2030',\n",
    " '222660ff',\n",
    " 'Chest Sorter (Assessment)_2010',\n",
    " 'Bird Measurer (Assessment)_4090',\n",
    " 'Flower Waterer (Activity)_4022',\n",
    " 'Dino Dive_2000',\n",
    " 'Welcome to Lost Lagoon!',\n",
    " 'Dino Dive_3121',\n",
    " 'f93fc684',\n",
    " 'Tree Top City - Level 1_2000',\n",
    " '4c2ec19f',\n",
    " '12 Monkeys',\n",
    " '9ce586dd',\n",
    " 'Bubble Bath_4040',\n",
    " 'Cauldron Filler (Assessment)_4025',\n",
    " 'b120f2ac',\n",
    " 'All Star Sorting_2025',\n",
    " 'c277e121',\n",
    " 'd9c005dd',\n",
    " 'All Star Sorting_4090',\n",
    " '53c6e11a',\n",
    " 'daac11b0',\n",
    " 'Chest Sorter (Assessment)_4030',\n",
    " 'Dino Dive_2020',\n",
    " 'Cauldron Filler (Assessment)_4070',\n",
    " '5e812b27',\n",
    " '3ddc79c3',\n",
    " '363c86c9',\n",
    " 'Crystals Rule_4090',\n",
    " '5be391b5',\n",
    " '1c178d24',\n",
    " 'Pan Balance_3021',\n",
    " '250513af',\n",
    " 'Bird Measurer (Assessment)_4040',\n",
    " 4220,\n",
    " 'Bubble Bath_4220',\n",
    " '736f9581',\n",
    " '9b23e8ee',\n",
    " 'Egg Dropper (Activity)_2000',\n",
    " '2dcad279',\n",
    " 'Costume Box',\n",
    " '37db1c2f',\n",
    " 'd3640339',\n",
    " 'Chest Sorter (Assessment)_2000',\n",
    " '155f62a4',\n",
    " 'Chest Sorter (Assessment)_2020',\n",
    " '1325467d',\n",
    " 'Chow Time_4030',\n",
    " 'c952eb01',\n",
    " 4235,\n",
    " '85de926c',\n",
    " 'ad148f58',\n",
    " 'Bubble Bath_4235',\n",
    " 'Bubble Bath_4230',\n",
    " '6d90d394',\n",
    " 'Bird Measurer (Assessment)_4020',\n",
    " 'Fireworks (Activity)_4030',\n",
    " '6aeafed4',\n",
    " 'b80e5e84',\n",
    " '1bb5fbdb',\n",
    " '262136f4',\n",
    " 'Dino Dive_2070',\n",
    " '15a43e5b',\n",
    " 'Heavy, Heavier, Heaviest',\n",
    " '3ccd3f02',\n",
    " '160654fd',\n",
    " 'Scrub-A-Dub_2030',\n",
    " '8d748b58',\n",
    " '2a444e03',\n",
    " 'c189aaf2',\n",
    " '49ed92e9',\n",
    " 'Crystals Rule_4020',\n",
    " 'Bird Measurer (Assessment)_2020',\n",
    " '0d18d96c',\n",
    " 'Bird Measurer (Assessment)_2000',\n",
    " 'f71c4741',\n",
    " 'abc5811c',\n",
    " '65abac75',\n",
    " '562cec5f',\n",
    " 'Chow Time_3010',\n",
    " 'a8876db3',\n",
    " '51311d7a',\n",
    " 'Leaf Leader_4010',\n",
    " '30614231',\n",
    " '28520915',\n",
    " 'Chow Time_2030',\n",
    " '8f094001',\n",
    " 'Bird Measurer (Assessment)_2030',\n",
    " '14de4c5d',\n",
    " 'Crystals Rule_3020',\n",
    " 'ad2fc29c',\n",
    " 'Scrub-A-Dub_2083',\n",
    " '76babcde',\n",
    " 'Crystals Rule_3121',\n",
    " 'Bubble Bath_2035',\n",
    " 'All Star Sorting_2000',\n",
    " 5010,\n",
    " 'Watering Hole (Activity)_5010',\n",
    " 'Pan Balance_4090',\n",
    " 'Bubble Bath_3121',\n",
    " 'Sandcastle Builder (Activity)_4020',\n",
    " 'Pan Balance_3010',\n",
    " 'Chow Time_3110',\n",
    " '3bb91ced',\n",
    " 'Dino Drink_2075',\n",
    " 'Chicken Balancer (Activity)_4070',\n",
    " 'Dino Drink_3010',\n",
    " 'Crystals Rule_4050',\n",
    " 4050,\n",
    " '47efca07',\n",
    " 'Leaf Leader_2060',\n",
    " 'Bird Measurer (Assessment)_3010',\n",
    " '6f4bd64e',\n",
    " 'Scrub-A-Dub_3021',\n",
    " 'de26c3a6',\n",
    " 'd2278a3b',\n",
    " 'Chow Time_4095',\n",
    " 'Happy Camel_3121',\n",
    " 'Bubble Bath_3010',\n",
    " 'd2e9262e',\n",
    " 'Flower Waterer (Activity)_4030',\n",
    " 'Treasure Map_2000',\n",
    " 'd3268efa',\n",
    " 'Mushroom Sorter (Assessment)_3120',\n",
    " 'Cauldron Filler (Assessment)_3120',\n",
    " 'Scrub-A-Dub_3120',\n",
    " 'Mushroom Sorter (Assessment)_4020',\n",
    " 'Cart Balancer (Assessment)_3110',\n",
    " 'Bubble Bath_2025',\n",
    " 'c54cf6c5',\n",
    " 'Bubble Bath_4020',\n",
    " 'e7561dd2',\n",
    " 'Cart Balancer (Assessment)_4090',\n",
    " '363d3849',\n",
    " 'Dino Drink_4020',\n",
    " 'Balancing Act',\n",
    " 'Bottle Filler (Activity)_4030',\n",
    " 'd45ed6a1',\n",
    " 'Dino Drink_2070',\n",
    " 'Leaf Leader_4070',\n",
    " 'All Star Sorting_3121',\n",
    " 'Bird Measurer (Assessment)_2010',\n",
    " '37ee8496',\n",
    " 'Watering Hole (Activity)_2000',\n",
    " 'Dino Drink_3021',\n",
    " '92687c59',\n",
    " 'c58186bf',\n",
    " 'ecc36b7f',\n",
    " 'e04fb33d',\n",
    " 'Bird Measurer (Assessment)_4035',\n",
    " '565a3990',\n",
    " 'Air Show_4110',\n",
    " 'f806dc10',\n",
    " 'Cart Balancer (Assessment)_4100',\n",
    " '3edf6747',\n",
    " '46cd75b4',\n",
    " 'Bottle Filler (Activity)_4020',\n",
    " 'a1bbe385',\n",
    " 'Leaf Leader_2020',\n",
    " 'b5053438',\n",
    " '9c5ef70c',\n",
    " 'Pan Balance_3120',\n",
    " 'c1cac9a2',\n",
    " \"Pirate's Tale\",\n",
    " '5859dfb6',\n",
    " 'Bubble Bath_3020',\n",
    " '8b757ab8',\n",
    " '832735e1',\n",
    " '461eace6',\n",
    " 'bbfe0445',\n",
    " '0086365d',\n",
    " 'd02b7a8e',\n",
    " '9e34ea74',\n",
    " '27253bdc',\n",
    " 'Pan Balance_3020',\n",
    " 'Flower Waterer (Activity)_4025',\n",
    " 'Mushroom Sorter (Assessment)_3110',\n",
    " 'Mushroom Sorter (Assessment)_4025',\n",
    " 'Crystals Rule_2000',\n",
    " 'Leaf Leader_3121',\n",
    " 'Tree Top City - Level 3_2000',\n",
    " 'Happy Camel_4040',\n",
    " '2fb91ec1',\n",
    " '93b353f2',\n",
    " 'Crystals Rule_4070',\n",
    " '3babcb9b',\n",
    " 'Cart Balancer (Assessment)_4030',\n",
    " 'Leaf Leader_3120',\n",
    " 'Dino Drink_4030',\n",
    " '63f13dd7',\n",
    " 'Mushroom Sorter (Assessment)_2000',\n",
    " '3bfd1a65',\n",
    " 'db02c830',\n",
    " 'c7fe2a55',\n",
    " '1996c610',\n",
    " 4031,\n",
    " 'Cauldron Filler (Assessment)_4090',\n",
    " '884228c8',\n",
    " 'Scrub-A-Dub_3110',\n",
    " '6c517a88',\n",
    " 'Bottle Filler (Activity)_3010',\n",
    " 'e9c52111',\n",
    " 'All Star Sorting_2020',\n",
    " '2b9272f4',\n",
    " 'Watering Hole (Activity)_4090',\n",
    " '90d848e0',\n",
    " 'Sandcastle Builder (Activity)_4021',\n",
    " 'Chow Time_2000',\n",
    " 'Egg Dropper (Activity)_3010',\n",
    " 'Leaf Leader_4090',\n",
    " '8ac7cce4',\n",
    " '9e4c8c7b',\n",
    " 'Cauldron Filler (Assessment)_3010',\n",
    " 'Happy Camel_2030',\n",
    " 'Bubble Bath_4070',\n",
    " 'Bird Measurer (Assessment)_4070',\n",
    " 'bc8f2793',\n",
    " 'Scrub-A-Dub_4020',\n",
    " 'Bird Measurer (Assessment)_4100',\n",
    " 'Happy Camel_3110',\n",
    " '5de79a6a',\n",
    " 'Fireworks (Activity)_2000',\n",
    " 'Bubble Bath_2020',\n",
    " 'Happy Camel_4095',\n",
    " 'Chest Sorter (Assessment)_3020',\n",
    " 'Dino Drink_2060',\n",
    " 'Chow Time_3020',\n",
    " '022b4259',\n",
    " 'Cauldron Filler (Assessment)_2020',\n",
    " 'Dino Dive_3020',\n",
    " '9d29771f',\n",
    " 'd88ca108',\n",
    " 'c2baf0bd',\n",
    " 'Flower Waterer (Activity)_4070',\n",
    " 'Air Show_4070',\n",
    " 'e694a35b',\n",
    " '6c930e6e',\n",
    " 'Watering Hole (Activity)_3110',\n",
    " 'Bug Measurer (Activity)_2000',\n",
    " 'a5e9da97',\n",
    " '763fc34e',\n",
    " 'Dino Dive_4020',\n",
    " 'b88f38da',\n",
    " 'Happy Camel_3020',\n",
    " 'Fireworks (Activity)_4090',\n",
    " 'Air Show_2060',\n",
    " 'Chest Sorter (Assessment)_4040',\n",
    " 'Bubble Bath_2030',\n",
    " 'Air Show_4020',\n",
    " '9b01374f',\n",
    " '99ea62f3',\n",
    " '4ef8cdd3',\n",
    " 'Happy Camel_3120',\n",
    " '85d1b0de',\n",
    " 'Chest Sorter (Assessment)_3121',\n",
    " 'Chest Sorter (Assessment)_3021',\n",
    " 'All Star Sorting_4020',\n",
    " 'Slop Problem',\n",
    " '56cd3b43',\n",
    " 'Sandcastle Builder (Activity)_4090',\n",
    " 'Air Show_3010',\n",
    " 'Scrub-A-Dub_4010',\n",
    " 'c7128948',\n",
    " 'Crystal Caves - Level 3_2000',\n",
    " 'b1d5101d',\n",
    " 'Magma Peak - Level 2',\n",
    " '6f8106d9',\n",
    " 'Pan Balance_4020',\n",
    " 'Chicken Balancer (Activity)_4030',\n",
    " 'Ordering Spheres_2000',\n",
    " 'Happy Camel_4035',\n",
    " '04df9b66',\n",
    " '15f99afc',\n",
    " 'cdd22e43',\n",
    " '7da34a02',\n",
    " 'bdf49a58',\n",
    " 'Bug Measurer (Activity)_3010',\n",
    " '7f0836bf',\n",
    " 'Magma Peak - Level 1',\n",
    " '28a4eb9a',\n",
    " 'Happy Camel_4020',\n",
    " 'Air Show_2030',\n",
    " '33505eae',\n",
    " '31973d56',\n",
    " '17113b36',\n",
    " '2230fab4',\n",
    " '3b2048ee',\n",
    " 'Chow Time_3021',\n",
    " 'Pan Balance_4070',\n",
    " 'Happy Camel_4030',\n",
    " '5348fd84',\n",
    " 'Mushroom Sorter (Assessment)_4090',\n",
    " 'beb0a7b9',\n",
    " '16dffff1',\n",
    " 'Scrub-A-Dub_2080',\n",
    " 'Bubble Bath_2000',\n",
    " 'Egg Dropper (Activity)_4090',\n",
    " 'bd612267',\n",
    " 'Rulers_2000',\n",
    " 'd88e8f25',\n",
    " 'fbaf3456',\n",
    " '1575e76c',\n",
    " 'Chicken Balancer (Activity)_3010',\n",
    " 'Sandcastle Builder (Activity)_2000',\n",
    " '47f43a44',\n",
    " 'Chicken Balancer (Activity)_4020',\n",
    " 'Lifting Heavy Things_2000',\n",
    " '71fe8f75',\n",
    " 'Chicken Balancer (Activity)_2000',\n",
    " 'Honey Cake_2000',\n",
    " 'c74f40cd',\n",
    " '5154fc30',\n",
    " 'Cauldron Filler (Assessment)_4100',\n",
    " 'Crystals Rule_2030',\n",
    " 'Mushroom Sorter (Assessment)_3010',\n",
    " '00c73085',\n",
    " 'e37a2b78',\n",
    " 'Air Show_2075',\n",
    " 'a592d54e',\n",
    " '99abe2bb',\n",
    " '795e4a37',\n",
    " 'Bottle Filler (Activity)_3110',\n",
    " 'Bird Measurer (Assessment)_4025',\n",
    " 'Dino Dive_4010',\n",
    " '8d7e386c',\n",
    " 'All Star Sorting_4070',\n",
    " 'Crystal Caves - Level 2_2000',\n",
    " 'Happy Camel_4070',\n",
    " 'Watering Hole (Activity)_5000',\n",
    " 'a6d66e51',\n",
    " 'b7530680',\n",
    " 'Cart Balancer (Assessment)_4035',\n",
    " 'df4fe8b6',\n",
    " 'd185d3ea',\n",
    " 'Dino Dive_3110',\n",
    " 'Bubble Bath_3021',\n",
    " 'sum_event_code_count',\n",
    " '19967db1',\n",
    " '15ba1109',\n",
    " 'Watering Hole (Activity)_4021',\n",
    " '2a512369',\n",
    " 'All Star Sorting_4010',\n",
    " 'Dino Dive_2060',\n",
    " 'Leaf Leader_2070',\n",
    " 'All Star Sorting_2030',\n",
    " 'Cart Balancer (Assessment)_4020',\n",
    " 'b2dba42b',\n",
    " '84b0e0c8',\n",
    " 'Tree Top City - Level 2',\n",
    " '2b058fe3',\n",
    " 'Chow Time_4070',\n",
    " '7423acbc',\n",
    " 'dcaede90',\n",
    " 2040,\n",
    " 'e3ff61fb',\n",
    " 'Crystal Caves - Level 1',\n",
    " 'd3f1e122',\n",
    " 'cb1178ad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 403 features!\n"
     ]
    }
   ],
   "source": [
    "print(\"Deleting \" + str(len(del_cols)) + \" features!\")\n",
    "reduce_train.drop(del_cols, inplace = True, axis = \"columns\")\n",
    "reduce_test.drop(del_cols, inplace = True, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cappa loss helper method defination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function Decleration\n",
    "def qwk_loss(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return 1 - o / e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We Gonna have float values as predictions from our regression model so this is an helper function to convert these float values into labels 0,1,2,3 according to certain thresholds!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_resl_to_label(true_labels, preds_labels):\n",
    "    preds_labels[preds_labels <= 1.12232214] = 0\n",
    "    preds_labels[np.where(np.logical_and(preds_labels > 1.12232214, preds_labels <= 1.73925866))] = 1\n",
    "    preds_labels[np.where(np.logical_and(preds_labels > 1.73925866, preds_labels <= 2.22506454))] = 2\n",
    "    preds_labels[preds_labels > 2.22506454] = 3\n",
    "    return 'cappa', qwk_loss(true_labels, preds_labels), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method to train model that can be tweaked to be used by multiple other datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def train_model(X: pd.DataFrame,\n",
    "                y,\n",
    "            folds = None,\n",
    "            params: dict = None,\n",
    "            del_cols: list = None):\n",
    "\n",
    "    \"\"\"Basic parameters\n",
    "        1. X: train_data\n",
    "        2. y: ground truth labels\n",
    "        3. params: lightGBM parameters\n",
    "        4. del_cols: columns to be avoided while training like accuracy_group must not be a column! \n",
    "    \"\"\"\n",
    "    global scores\n",
    "    eval_metric = regr_resl_to_label #custom metric as defined above\n",
    "    columns = [col for col in X.columns.values if not col in del_cols] #features\n",
    "    \n",
    "    models = [] #save n_folds models\n",
    "    n_target = 1 # number of targets\n",
    "    oof = np.zeros((len(X), n_target)) # out of fold predictions\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y, X['installation_id'])):\n",
    "        \n",
    "        print('Fold {} started at {}'.format(fold_n + 1,time.ctime()))\n",
    "        X_train, X_valid = X.loc[train_index,columns], X.loc[valid_index,columns]\n",
    "        y_train, y_valid = y.loc[train_index], y.loc[valid_index]\n",
    "        print(X_train.shape)\n",
    "        \n",
    "        #Eval set preparation\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        eval_set.append((X_valid, y_valid))\n",
    "        eval_names.append('valid')\n",
    "        categorical_columns = 'auto'\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_metric,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "        \n",
    "        oof[valid_index] = model.predict(X_valid).reshape(-1, n_target)\n",
    "        score = regr_resl_to_label(X.loc[valid_index,\"accuracy_group\"],oof[valid_index])\n",
    "        scores.append(score)\n",
    "        models.append(model)\n",
    "    scores = [score[1][0] for score in scores]\n",
    "    print(scores)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**very simple prediction method, Just get the results from multiple models from different folds and average them all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, X_test, averaging: str = 'usual'):\n",
    "    full_prediction = np.zeros((X_test.shape[0], 1))\n",
    "    for i in range(len(models)):\n",
    "        X_t = X_test.copy()\n",
    "        if cols_to_drop is not None:\n",
    "            del_cols = [col for col in cols_to_drop if col in X_t.columns.values]\n",
    "            X_t = X_t.drop(del_cols, axis=1)\n",
    "        y_pred = models[i].predict(X_t).reshape(-1, full_prediction.shape[1])\n",
    "        if full_prediction.shape[0] != len(y_pred):\n",
    "            full_prediction = np.zeros((y_pred.shape[0], 1))\n",
    "        if averaging == 'usual':\n",
    "            full_prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            full_prediction += pd.Series(y_pred).rank().values\n",
    "    return full_prediction / len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My best parameters found by many parameter tuning techniques and less overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'verbose': 100,\n",
    "          'learning_rate': 0.010514633017309072,\n",
    "          'metric': 'rmse',\n",
    "          'bagging_freq': 3,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'eval_metric': 'cappa',\n",
    "          'lambda_l1': 4.8999704874480745,\n",
    "          'colsample_bytree': 0.4236269531042225,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'max_depth': 12,\n",
    "          'lambda_l2': 0.054084652510602016,\n",
    "          'bagging_fraction': 0.7931423220563563,\n",
    "          'n_jobs': -1,\n",
    "          'n_estimators': 2000,\n",
    "          'objective': 'regression',\n",
    "          'seed': 42}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may get Light gbm error regarding special json characters in names of some columns**\n",
    "\n",
    "These two lines will get deal with those errors for you :)\n",
    "\n",
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sun Dec 15 08:02:00 2019\n",
      "(14152, 441)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.07733\ttrain's cappa: 0.46883\tvalid's rmse: 1.09718\tvalid's cappa: 0.443364\n",
      "[200]\ttrain's rmse: 0.995906\ttrain's cappa: 0.614059\tvalid's rmse: 1.03227\tvalid's cappa: 0.568282\n",
      "[300]\ttrain's rmse: 0.951165\ttrain's cappa: 0.654268\tvalid's rmse: 1.00347\tvalid's cappa: 0.598592\n",
      "[400]\ttrain's rmse: 0.922111\ttrain's cappa: 0.673092\tvalid's rmse: 0.988236\tvalid's cappa: 0.614281\n",
      "[500]\ttrain's rmse: 0.90148\ttrain's cappa: 0.68664\tvalid's rmse: 0.981241\tvalid's cappa: 0.618828\n",
      "[600]\ttrain's rmse: 0.884281\ttrain's cappa: 0.698081\tvalid's rmse: 0.976476\tvalid's cappa: 0.619236\n",
      "Early stopping, best iteration is:\n",
      "[557]\ttrain's rmse: 0.891519\ttrain's cappa: 0.693657\tvalid's rmse: 0.978499\tvalid's cappa: 0.621845\n",
      "Fold 2 started at Sun Dec 15 08:03:11 2019\n",
      "(14152, 441)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.07416\ttrain's cappa: 0.472705\tvalid's rmse: 1.1103\tvalid's cappa: 0.401598\n",
      "[200]\ttrain's rmse: 0.99385\ttrain's cappa: 0.613878\tvalid's rmse: 1.04513\tvalid's cappa: 0.545929\n",
      "[300]\ttrain's rmse: 0.950533\ttrain's cappa: 0.653664\tvalid's rmse: 1.01439\tvalid's cappa: 0.58169\n",
      "[400]\ttrain's rmse: 0.92205\ttrain's cappa: 0.673447\tvalid's rmse: 0.998911\tvalid's cappa: 0.595701\n",
      "[500]\ttrain's rmse: 0.901968\ttrain's cappa: 0.687904\tvalid's rmse: 0.990732\tvalid's cappa: 0.602704\n",
      "[600]\ttrain's rmse: 0.884728\ttrain's cappa: 0.700615\tvalid's rmse: 0.985\tvalid's cappa: 0.608383\n",
      "[700]\ttrain's rmse: 0.869976\ttrain's cappa: 0.712438\tvalid's rmse: 0.98191\tvalid's cappa: 0.613873\n",
      "[800]\ttrain's rmse: 0.857007\ttrain's cappa: 0.722197\tvalid's rmse: 0.980569\tvalid's cappa: 0.618091\n",
      "[900]\ttrain's rmse: 0.844932\ttrain's cappa: 0.7315\tvalid's rmse: 0.97998\tvalid's cappa: 0.618245\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttrain's rmse: 0.854347\ttrain's cappa: 0.724014\tvalid's rmse: 0.980294\tvalid's cappa: 0.61882\n",
      "Fold 3 started at Sun Dec 15 08:04:49 2019\n",
      "(14152, 441)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.07912\ttrain's cappa: 0.469932\tvalid's rmse: 1.08053\tvalid's cappa: 0.42429\n",
      "[200]\ttrain's rmse: 0.996914\ttrain's cappa: 0.615465\tvalid's rmse: 1.01922\tvalid's cappa: 0.561268\n",
      "[300]\ttrain's rmse: 0.952286\ttrain's cappa: 0.655359\tvalid's rmse: 0.991845\tvalid's cappa: 0.587725\n",
      "[400]\ttrain's rmse: 0.923029\ttrain's cappa: 0.67669\tvalid's rmse: 0.979048\tvalid's cappa: 0.599653\n",
      "[500]\ttrain's rmse: 0.902306\ttrain's cappa: 0.689577\tvalid's rmse: 0.973496\tvalid's cappa: 0.602437\n",
      "[600]\ttrain's rmse: 0.885386\ttrain's cappa: 0.702783\tvalid's rmse: 0.970845\tvalid's cappa: 0.602711\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttrain's rmse: 0.895783\ttrain's cappa: 0.694213\tvalid's rmse: 0.972314\tvalid's cappa: 0.603855\n",
      "Fold 4 started at Sun Dec 15 08:06:00 2019\n",
      "(14152, 441)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.07286\ttrain's cappa: 0.480033\tvalid's rmse: 1.1056\tvalid's cappa: 0.424602\n",
      "[200]\ttrain's rmse: 0.990565\ttrain's cappa: 0.615763\tvalid's rmse: 1.04538\tvalid's cappa: 0.55408\n",
      "[300]\ttrain's rmse: 0.945981\ttrain's cappa: 0.658755\tvalid's rmse: 1.01892\tvalid's cappa: 0.582667\n",
      "[400]\ttrain's rmse: 0.917029\ttrain's cappa: 0.677117\tvalid's rmse: 1.00642\tvalid's cappa: 0.586651\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttrain's rmse: 0.925757\ttrain's cappa: 0.672462\tvalid's rmse: 1.00962\tvalid's cappa: 0.590254\n",
      "Fold 5 started at Sun Dec 15 08:06:52 2019\n",
      "(14152, 441)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.07006\ttrain's cappa: 0.484747\tvalid's rmse: 1.1143\tvalid's cappa: 0.406731\n",
      "[200]\ttrain's rmse: 0.98682\ttrain's cappa: 0.62398\tvalid's rmse: 1.05617\tvalid's cappa: 0.532139\n",
      "[300]\ttrain's rmse: 0.941211\ttrain's cappa: 0.663398\tvalid's rmse: 1.03087\tvalid's cappa: 0.561573\n",
      "[400]\ttrain's rmse: 0.911845\ttrain's cappa: 0.682923\tvalid's rmse: 1.01928\tvalid's cappa: 0.569771\n",
      "[500]\ttrain's rmse: 0.891262\ttrain's cappa: 0.695002\tvalid's rmse: 1.01417\tvalid's cappa: 0.578123\n",
      "[600]\ttrain's rmse: 0.87383\ttrain's cappa: 0.707309\tvalid's rmse: 1.01116\tvalid's cappa: 0.579307\n",
      "[700]\ttrain's rmse: 0.85895\ttrain's cappa: 0.717044\tvalid's rmse: 1.0098\tvalid's cappa: 0.580333\n",
      "[800]\ttrain's rmse: 0.84556\ttrain's cappa: 0.727319\tvalid's rmse: 1.00923\tvalid's cappa: 0.580245\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttrain's rmse: 0.852733\ttrain's cappa: 0.721909\tvalid's rmse: 1.00948\tvalid's cappa: 0.582736\n",
      "[0.621844996017809, 0.618820303342466, 0.6038547688192633, 0.590253876104043, 0.5827358403889917]\n"
     ]
    }
   ],
   "source": [
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]\n",
    "\n",
    "# no need for these columns in training\n",
    "cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate'] + [col for col in reduce_train.columns.values if \"_time\" in str(col)]#ground truth fact labels\n",
    "y = reduce_train['accuracy_group']\n",
    "#group k-fold and please don't go for just k-fold\n",
    "n_fold = 5\n",
    "folds = GroupKFold(n_splits=n_fold)\n",
    "models = train_model(X = reduce_train, y = y,folds = folds, params = params, del_cols = cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(models, reduce_test)\n",
    "    \n",
    "coefficients = [1.12232214, 1.73925866, 2.22506454]\n",
    "preds[preds <= coefficients[0]] = 0\n",
    "preds[np.where(np.logical_and(preds > coefficients[0], preds <= coefficients[1]))] = 1\n",
    "preds[np.where(np.logical_and(preds > coefficients[1], preds <= coefficients[2]))] = 2\n",
    "preds[preds > coefficients[2]] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.331\n",
       "3    0.324\n",
       "1    0.182\n",
       "0    0.163\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['accuracy_group'] = preds.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
